ğŸ§  Glassdoor Sentiment Analysis

This project analyzes employee reviews from Glassdoor to classify overall sentiment (Positive / Neutral / Negative) and uncover insights about workplace culture, management, and job satisfaction. It demonstrates an end-to-end Natural Language Processing (NLP) workflow â€” from raw text preprocessing to model deployment â€” using modern deep learning architectures.

ğŸš€ Project Overview

The goal is to build an intelligent system that can automatically determine employee sentiment based on textual reviews.
The project was implemented in two phases to showcase the evolution from traditional NLP methods to advanced transformer-based models.

ğŸ”¹ Phase 1 â€” LSTM + GloVe

Built an LSTM model using pre-trained GloVe embeddings.

Achieved 87% validation accuracy on cleaned review text.

ğŸ”¹ Phase 2 â€” Fine-Tuned BERT

Leveraged Hugging Face Transformers and PyTorch to fine-tune a BERT model.

Achieved 90% validation accuracy, improving performance by 7%.

Added Dropout layers and applied hyperparameter tuning to reduce overfitting.

âš™ï¸ Key Features

End-to-end NLP pipeline: Data cleaning, preprocessing, embedding, model training, and deployment.

Feature engineering: Compared TF-IDF, Word2Vec (GloVe), and BERT embeddings.

Interactive deployment: Real-time prediction web app built with Streamlit.

Dashboard insights: Sentiment trends by company, job title, and location.

Scalable architecture: Modular file structure with reusable scripts for preprocessing, modeling, and visualization.

ğŸ§© Tech Stack

Languages & Libraries:

Python, PyTorch, TensorFlow, Scikit-learn, Hugging Face Transformers

Pandas, NumPy, Matplotlib, Seaborn, NLTK, Gensim

Streamlit for deployment

ğŸ“Š Results
Model	Embedding	Accuracy	Framework
LSTM	GloVe	87%	TensorFlow
BERT	Transformer (Fine-tuned)	90%	PyTorch
ğŸ“ Project Structure
Glassdoor-Sentiment-Analysis/
â”‚
â”œâ”€â”€ ğŸ“„ README.md
â”‚
â”œâ”€â”€ ğŸ“Š Dashboards/
â”‚   â””â”€â”€ Glassdoor Dashboard.pbix
â”‚
â”œâ”€â”€ ğŸ“ Data/
â”‚   â”œâ”€â”€ Analysis_data_.csv
â”‚   â”œâ”€â”€ glassdoor_reviews.csv
â”‚   â””â”€â”€ Sentiment_data_2.csv
â”‚
â”œâ”€â”€ ğŸ–¼ï¸ Images/
â”‚   â””â”€â”€ (dashboard template, icons, images)
â”‚
â”œâ”€â”€ ğŸ§© Phase 1/                # LSTM + GloVe (TensorFlow)
â”‚   â”œâ”€â”€ ğŸ“‚ Glove/
â”‚   â”‚   â””â”€â”€ wiki_giga_2024_100_MFT20_vectors_seed_2024_alpha_0.75_eta_0.05.050_combined.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Models/
â”‚   â”‚   â”œâ”€â”€ sentiment_model_0.87.keras
â”‚   â”‚   â””â”€â”€ tokenizer.pkl
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ““ Notebooks/
â”‚   â”‚   â”œâ”€â”€ Base_line_models.ipynb
â”‚   â”‚   â””â”€â”€ Data_Preparation.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ âš™ï¸ Src/
â”‚       â”œâ”€â”€ data_preprocessing.py
â”‚       â”œâ”€â”€ evaluate.py
â”‚       â”œâ”€â”€ feature_engineering.py
â”‚       â”œâ”€â”€ model.py
â”‚       â”œâ”€â”€ sentiment_utils.py
â”‚       â””â”€â”€ train.py
â”‚
â”œâ”€â”€ ğŸ¤– Phase 2/                # Fine-tuned BERT (PyTorch + Hugging Face)
â”‚   â”œâ”€â”€ ğŸ“‚ Models/
â”‚   â”‚   â”œâ”€â”€ BERT model/
â”‚   â”‚   â””â”€â”€ distilbert BERT model/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ““ Notebooks/
â”‚   â”‚   â””â”€â”€ model_preparation.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ âš™ï¸ Src/
â”‚       â”œâ”€â”€ data_preprocessing.py
â”‚       â”œâ”€â”€ glassdoor_dataset_class.py
â”‚       â”œâ”€â”€ model.py
â”‚       â”œâ”€â”€ Streamlit web app.py
â”‚       â”œâ”€â”€ test.py
â”‚       â””â”€â”€ train.py

ğŸ’¡ Insights & Learnings

Learned to combine NLP preprocessing with deep learning architectures.

Observed how transfer learning (BERT) significantly improves generalization.

Enhanced model interpretability through sentiment visualization.

Built modular, production-ready ML pipelines.

ğŸŒ Deployment

The project is deployed using Streamlit, providing:

Real-time text sentiment classification.

Visual analytics for review trends.

Interactive UI for exploring model predictions.